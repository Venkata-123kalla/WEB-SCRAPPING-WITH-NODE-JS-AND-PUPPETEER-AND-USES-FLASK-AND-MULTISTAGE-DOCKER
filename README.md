# WEB-SCRAPPING-WITH-NODE-JS-AND-PUPPETEER-AND-USES-FLASK-AND-MULTISTAGE-DOCKER

# ‚úÖ Task 1: Node.js Scraper with Puppeteer

### üéØ Objective

Develop a Node.js application that:

- Accepts a dynamic URL (via an environment variable).
- Uses Puppeteer with a headless Chromium browser to load the page.
- Extracts key details such as:
  - The page title
  - The first `<h1>` heading (if available)
- Saves the extracted data in JSON format to `scraped_data.json`.

---

### üõ†Ô∏è Technologies Used

- **Node.js** ‚Äì JavaScript runtime for writing backend logic.
- **Puppeteer** ‚Äì A Node.js library for controlling headless Chromium.
- **Chromium** ‚Äì The open-source version of Chrome, used for scraping.
- **Docker** ‚Äì To containerize the scraper logic with all dependencies.

### create scrape.js file 
### create Docker image with the help of Dockerfile
- docker build -t image_name .

![Screenshot](Screenshot (722).png)

### After cretaing image then run the conatiner and will see the output
![Screenshot](https://github.com/Venkata-123kalla/WEB-SCRAPPING-WITH-NODE-JS-AND-PUPPETEER-AND-USES-FLASK-AND-MULTISTAGE-DOCKER/blob/master/Screenshot%20(722).png?raw=true)

### The web-scrapping contents will be copied or extracted into the scraped_data.json file


# üêç Task 2 ‚Äì Python Hosting Stage with Flask(mkdir exercise)

## üìå Objective

Build a lightweight Python Flask server that reads the previously scraped **Amazon Best Sellers** data from `scraped_data.json` and exposes it through a **REST API**.

---

## üõ†Ô∏è Technologies Used

- **Python 3.10-slim** (Base Docker Image)
- **Flask** ‚Äì Python micro web framework
- **Docker** ‚Äì Multi-stage Docker build combining Node.js & Python environments

---

## steps to do the python hosting stage
- code will be available in the  git repo mkdir exercise
- Base image: Use a Python (e.g., python:3.10-slim) image.
- Copy the scraped_data.json from the previous stage
- Implement a simple Flask application (server.py) that: 
  - Reads the JSON file. 
  - Provides an HTTP endpoint (e.g., at /) that returns the scraped content as JSON. 
![Screenshot](https://github.com/Venkata-123kalla/WEB-SCRAPPING-WITH-NODE-JS-AND-PUPPETEER-AND-USES-FLASK-AND-MULTISTAGE-DOCKER/blob/master/Screenshot%20(727).png?raw=true)

- Build Docker image and create conatiner and run it
![Screenshot](https://github.com/Venkata-123kalla/WEB-SCRAPPING-WITH-NODE-JS-AND-PUPPETEER-AND-USES-FLASK-AND-MULTISTAGE-DOCKER/blob/master/Screenshot%20(730).png?raw=true)

- Expose port 5000 : http://<public-ip-ec2>:5000
![Screenshot](https://github.com/Venkata-123kalla/WEB-SCRAPPING-WITH-NODE-JS-AND-PUPPETEER-AND-USES-FLASK-AND-MULTISTAGE-DOCKER/blob/master/Screenshot%20(731).png?raw=true)

 
# üì¶ Task 3 ‚Äì Multi-Stage Dockerfile for Web Scraping & Hosting

## üéØ Objective

Combine the web scraping (Node.js + Puppeteer) and Flask-based API server into a single container using **multi-stage Docker builds**. The goal is to optimize the final image size by including only the essential runtime components.

---

## üß∞ Technologies Used

- **Node.js** ‚Äì For web scraping using Puppeteer
- **Python 3.10-slim** ‚Äì For hosting a Flask API
- **Docker** ‚Äì Multi-stage builds to separate build and runtime environments

---

## üîÄ Multi-Stage Dockerfile

### Directory multi consists files that are used to complete the task
- The directory consists of 
- Dockerfile: A multi-stage Dockerfile that builds the complete application
- scrape.js: Node.js script that uses Puppeteer to scrape a given URL
- server.py: Python Flask application that serves the scraped data. 
- package.json: For Node dependencies

## create an image with the help of Dockerfile
- docker build --build-arg SCRAPE_URL="https://github.com" -t multi-scraper .
- docker run -p 5000:5000 multi-scraper


![Screenshot](https://github.com/Venkata-123kalla/WEB-SCRAPPING-WITH-NODE-JS-AND-PUPPETEER-AND-USES-FLASK-AND-MULTISTAGE-DOCKER/blob/master/Screenshot%20(735).png?raw=true)

## if we want to see the scarped_data.json file we have to login to the conatiner witl the help of these commands
- docker start container-id && docker exec -it containner-id /bin/bash
![Screenshot](https://github.com/Venkata-123kalla/WEB-SCRAPPING-WITH-NODE-JS-AND-PUPPETEER-AND-USES-FLASK-AND-MULTISTAGE-DOCKER/blob/master/Screenshot%20(735).png?raw=true)

## if we want to see the output of the flask server
- use http://<public-ip-ec2>:5000

![Screenshot](https://github.com/Venkata-123kalla/WEB-SCRAPPING-WITH-NODE-JS-AND-PUPPETEER-AND-USES-FLASK-AND-MULTISTAGE-DOCKER/blob/master/Screenshot%20(739).png?raw=true)



